{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5f3MY4iTdY_"
      },
      "source": [
        "# Fine-tune LLMs to do Sarcasm Detections and Interpretations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EpjWNrb6GqXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ba66e5-fa9b-41ac-ac26-80efcdfa1ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: comet-ml in /usr/local/lib/python3.10/dist-packages (3.47.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: unbabel-comet in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: everett<3.2.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (3.1.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (4.23.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (5.9.5)\n",
            "Requirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (6.1.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.32.3)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.18.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.19.3)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (2.2.3)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (1.16.0)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (3.1.1)\n",
            "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (0.22.5)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml) (13.9.4)\n",
            "Requirement already satisfied: entmax<2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.26.2)\n",
            "Requirement already satisfied: jsonargparse==3.13.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (3.13.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.2.2)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (4.25.5)\n",
            "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.4.0)\n",
            "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.4.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.96 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (0.10.3)\n",
            "Requirement already satisfied: transformers<5.0,>=4.17 in /usr/local/lib/python3.10/dist-packages (from unbabel-comet) (4.46.2)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: configobj in /usr/local/lib/python3.10/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet-ml) (5.0.9)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet) (4.12.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml) (0.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.1->unbabel-comet) (2024.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.11.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet-ml) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml) (2.18.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (2.10.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (5.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->unbabel-comet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (75.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml) (0.1.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->unbabel-comet) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk comet-ml emoji unbabel-comet datasets evaluate rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5JF4MaIAGBUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef14c28a-d43a-4e3e-9d82-b371f93566d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Current working directory: /content/drive/MyDrive/Context_Aware\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the target directory path\n",
        "target_dir = '/content/drive/MyDrive/Context_Aware'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(target_dir):\n",
        "    os.makedirs(target_dir)\n",
        "\n",
        "# Change the working directory to the target directory\n",
        "os.chdir(target_dir)\n",
        "\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "35JsWx2OFaxk"
      },
      "outputs": [],
      "source": [
        "#model_choice = 'gpt2'\n",
        "#model_choice = 'flan-t5-base'\n",
        "model_choice = 't5-base'\n",
        "classifier_model_choice = 'bert-base-uncased'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w4-U-25iLWIH"
      },
      "outputs": [],
      "source": [
        "mode = 'train'\n",
        "# mode = 'evaluate'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lMBGEMhQO14U"
      },
      "outputs": [],
      "source": [
        "#dataset_ = 'iSarcasm'\n",
        "# dataset_ = 'GPT-4o-mini'\n",
        "dataset_ = 'combined_train_df'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t9q8GFYTdZC"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSW3qxsmPrRK"
      },
      "source": [
        "### Classfication Model: bert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M-dveR0VPqC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8bdd53-6b29-4c7b-bcba-3ecdb37c51fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# initialize tokenizer and model for Sarcasm Detection\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "if mode == 'train':\n",
        "  classifier_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  classifier_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "else:\n",
        "  classifier_tokenizer = BertTokenizer.from_pretrained(f'./results/{classifier_model_choice}/my_model')\n",
        "  classifier_model = BertForSequenceClassification.from_pretrained(f'./results/{classifier_model_choice}/my_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xASrnpTNTdZD"
      },
      "source": [
        "### GPT-2 small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e43dmLCyTdZD"
      },
      "outputs": [],
      "source": [
        "if model_choice == 'gpt2':\n",
        "  from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "  if mode == 'train':\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "  else:\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(f'./results/{model_choice}/my_model')\n",
        "    model = GPT2LMHeadModel.from_pretrained(f'./results/{model_choice}/my_model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl3dt9S4TdZF"
      },
      "source": [
        "### Google FLAN-T5-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Vmie6yPATdZF"
      },
      "outputs": [],
      "source": [
        "if model_choice == 'flan-t5-base':\n",
        "  from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "  if mode == 'train':\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
        "  else:\n",
        "    tokenizer = T5Tokenizer.from_pretrained(f'./results/{model_choice}/my_model')\n",
        "    model = T5ForConditionalGeneration.from_pretrained(f'./results/{model_choice}/my_model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSA9hIn0TdZG"
      },
      "source": [
        "### T5-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ynp29onqTdZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e91f9028-34a1-45b6-f8f4-2ee082d901e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "if model_choice == 't5-base':\n",
        "  from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "  if mode == 'train':\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "  else:\n",
        "    tokenizer = T5Tokenizer.from_pretrained(f'./results/{model_choice}/my_model')\n",
        "    model = T5ForConditionalGeneration.from_pretrained(f'./results/{model_choice}/my_model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdR7px1KTdZG"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RTOxH0rSTdZG"
      },
      "outputs": [],
      "source": [
        "# loading combined_df dataset = isarcasm + gpt_pairs\n",
        "import pandas as pd\n",
        "def load_data():\n",
        "  dataset = pd.read_csv('combined_df.tsv', sep='\\t')\n",
        "  evaluation_dataset = pd.read_csv('iSarcasm_pairs_test.tsv', sep='\\t')\n",
        "  dataset['Translation'] = dataset['Translation'].fillna('')\n",
        "  evaluation_dataset['Translation'] = evaluation_dataset['Translation'].fillna('')\n",
        "  return dataset, evaluation_dataset\n",
        "\n",
        "df, df_eval = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D-Ban4TmfuMq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0580f15a-fb05-4f55-817b-c8ba1d35fe93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Sarcastic  \\\n",
              "0  I deeply regret downloading tiktok.....yet not...   \n",
              "1  It's been so lovely to see the world in blue a...   \n",
              "2  quackity stream is making me so genuinely happ...   \n",
              "3  Oh yeah, because staying up late is the best d...   \n",
              "4  Fantastic! I can't wait for the meeting just t...   \n",
              "\n",
              "                                         Translation  IsSarcastic  \n",
              "0                                                               0  \n",
              "1                                                               0  \n",
              "2                                                               0  \n",
              "3  Staying up late is not a good choice for my he...            1  \n",
              "4           Repeated discussions can feel tedious.\"             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a657b43c-238d-4462-a95e-159bd58575d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sarcastic</th>\n",
              "      <th>Translation</th>\n",
              "      <th>IsSarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I deeply regret downloading tiktok.....yet not...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It's been so lovely to see the world in blue a...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>quackity stream is making me so genuinely happ...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Oh yeah, because staying up late is the best d...</td>\n",
              "      <td>Staying up late is not a good choice for my he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fantastic! I can't wait for the meeting just t...</td>\n",
              "      <td>Repeated discussions can feel tedious.\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a657b43c-238d-4462-a95e-159bd58575d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a657b43c-238d-4462-a95e-159bd58575d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a657b43c-238d-4462-a95e-159bd58575d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8f2d6ea-47f0-4f2e-a484-d4d44c082f45\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8f2d6ea-47f0-4f2e-a484-d4d44c082f45')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8f2d6ea-47f0-4f2e-a484-d4d44c082f45 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5681,\n  \"fields\": [\n    {\n      \"column\": \"Sarcastic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5669,\n        \"samples\": [\n          \"What a wonderful honor! I can feel the sarcasm dripping!\",\n          \"Oh, how thrilling to realize I haven't finished my mini-project that I was supposed to do weeks ago!\",\n          \"@adorinqdwt @dwtridesgnf Yes the racist is so cool!!!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Translation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3113,\n        \"samples\": [\n          \"Ambiguities in communication are problematic.\",\n          \"The seminar lacks valuable information.\",\n          \"Hearing repeated stories is tiresome.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IsSarcastic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq24u_dOP6QS"
      },
      "source": [
        "## Classification model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLvOvnvdP7kC"
      },
      "source": [
        "### Intitialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HAHqD-bvP_uS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rqvvSX6nTdZH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(test_df['IsSarcastic']).count(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqFUGwuOlcyP",
        "outputId": "71ee4582-5840-48bd-bbe5-db34350415de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "248"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vQbRIGsiQF1z"
      },
      "outputs": [],
      "source": [
        "# Function to convert emojis to text, handling float values\n",
        "import emoji\n",
        "\n",
        "def convert_emojis(text):\n",
        "    # Check if text is a float (potentially NaN) and convert to string\n",
        "    if isinstance(text, float):\n",
        "        text = str(text)\n",
        "    return emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "\n",
        "# Apply emoji conversion to both input (sarcastic) and output (literal) text\n",
        "train_df['Sarcastic'] = train_df['Sarcastic'].apply(convert_emojis)\n",
        "valid_df['Sarcastic'] = valid_df['Sarcastic'].apply(convert_emojis)\n",
        "test_df['Sarcastic'] = test_df['Sarcastic'].apply(convert_emojis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Dq6ILRekQH_e"
      },
      "outputs": [],
      "source": [
        "# source text encoding with selecetd classifier tokenizer\n",
        "def encode_texts(texts, targets=None, tokenizer=None):\n",
        "    if targets is None:  # For single input (sarcasm detection)\n",
        "        return classifier_tokenizer(\n",
        "            texts.tolist(),\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "oX5-uEkRQKF4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Custom dataset class for sarcasm classification\n",
        "class SarcasmClassificationDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = encode_texts(texts.astype(str))\n",
        "        self.labels = torch.tensor(labels.values)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.texts['input_ids'][idx],\n",
        "            'attention_mask': self.texts['attention_mask'][idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SarcasmClassificationDataset(train_df['Sarcastic'], train_df['IsSarcastic'])\n",
        "valid_dataset = SarcasmClassificationDataset(valid_df['Sarcastic'], valid_df['IsSarcastic'])\n",
        "test_dataset = SarcasmClassificationDataset(test_df['Sarcastic'], test_df['IsSarcastic'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QzoDOLjQM7g"
      },
      "source": [
        "### Training of Sarcasm Detection model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KsWaFyX1QPcq"
      },
      "outputs": [],
      "source": [
        "# metric computation for sarcasm detection\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    # Extract predictions and labels\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "\n",
        "    # Return as dictionary\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uZnTT_uiQRpc"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "\n",
        "# Training args for classification/detection model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f'./results/{classifier_model_choice}',\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=9e-5,\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer for sarcasm classification\n",
        "trainer = Trainer(\n",
        "    model=classifier_model.to(device),\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        "    compute_metrics=compute_metrics       # Metrics function\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VN3cw203QTsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "21aa9011-9701-43af-c17c-6b77ebab3390"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1704' max='2272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1704/2272 01:49 < 00:36, 15.56 it/s, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.385000</td>\n",
              "      <td>0.374460</td>\n",
              "      <td>0.840070</td>\n",
              "      <td>0.987288</td>\n",
              "      <td>0.725857</td>\n",
              "      <td>0.836625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.380200</td>\n",
              "      <td>0.486349</td>\n",
              "      <td>0.831283</td>\n",
              "      <td>0.978723</td>\n",
              "      <td>0.716511</td>\n",
              "      <td>0.827338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.376200</td>\n",
              "      <td>0.385204</td>\n",
              "      <td>0.845343</td>\n",
              "      <td>0.967871</td>\n",
              "      <td>0.750779</td>\n",
              "      <td>0.845614</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if mode == 'train':\n",
        "  # Train the sarcasm classifier\n",
        "  trainer.train()\n",
        "  # Save the model\n",
        "  classifier_model.save_pretrained(f'./results/{classifier_model_choice}/my_model')\n",
        "  classifier_tokenizer.save_pretrained(f'./results/{classifier_model_choice}/my_model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "omfFhfC6jbNx",
        "outputId": "e161a88f-6d73-4ce3-e40c-1a82bde94175"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_metrics(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFfQqdRwjmKL",
        "outputId": "2de0948c-30e0-403b-fde8-e0bc3d15f2ff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8400702987697716,\n",
              " 'precision': 0.9872881355932204,\n",
              " 'recall': 0.7258566978193146,\n",
              " 'f1': 0.8366247755834829}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "N4rbWwc2QVoW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "5f55fc2c-3387-4527-ed72-fcf161571fe9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='72' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [72/72 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.37445953488349915, 'eval_accuracy': 0.8400702987697716, 'eval_precision': 0.9872881355932204, 'eval_recall': 0.7258566978193146, 'eval_f1': 0.8366247755834829, 'eval_runtime': 0.8758, 'eval_samples_per_second': 649.657, 'eval_steps_per_second': 82.206, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA7ONdyuQYZO"
      },
      "source": [
        "## Interpretation Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS-W87OVQjG6"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "J_dG5iegwafc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mmkhVWLKwafh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Z7I5o60-QhHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310d45fc-5862-46ac-8cf1-7bb7c700e926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3130, 3)\n"
          ]
        }
      ],
      "source": [
        "# Data loading for Interpretation model, only using the sarcastic statements\n",
        "df, df_eval = load_data()\n",
        "df = df[df['IsSarcastic'] == 1]\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yfPzkYEmQnYm"
      },
      "outputs": [],
      "source": [
        "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1mE-QdW2QUol"
      },
      "outputs": [],
      "source": [
        "add_prefix = lambda x: \"Provide straightforward, literal translations for this sarcastic comment: \" + x\n",
        "\n",
        "train_df['Input'] = train_df['Sarcastic'].apply(add_prefix)\n",
        "valid_df['Input'] = valid_df['Sarcastic'].apply(add_prefix)\n",
        "test_df['Input'] = test_df['Sarcastic'].apply(add_prefix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2k7_NsCmTdZH"
      },
      "outputs": [],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "def tokenize_data(df):\n",
        "    inputs = tokenizer(\n",
        "        df['Input'].tolist(),\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    targets = tokenizer(\n",
        "        df['Translation'].tolist(),\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Set padding tokens in targets to -100 to ignore them in loss calculation\n",
        "    targets['input_ids'][targets['input_ids'] == tokenizer.pad_token_id] = -100\n",
        "\n",
        "    return {\n",
        "        'input_ids': inputs['input_ids'],\n",
        "        'attention_mask': inputs['attention_mask'],\n",
        "        'labels': targets['input_ids'],\n",
        "    }\n",
        "\n",
        "# Tokenize train, validation, and test datasets\n",
        "train_encodings = tokenize_data(train_df)\n",
        "valid_encodings = tokenize_data(valid_df)\n",
        "test_encodings = tokenize_data(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xJP1O4ilTdZH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "class SarcasmTranslationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SarcasmTranslationDataset(train_encodings)\n",
        "valid_dataset = SarcasmTranslationDataset(valid_encodings)\n",
        "test_dataset = SarcasmTranslationDataset(test_encodings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFrUtrv0SAOe"
      },
      "source": [
        "### Prepare Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdvsHyUeUYAQ"
      },
      "source": [
        "For colab, need to install additional packages (already in conda environment.yml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YgbEHW5HR-xi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "093f88ead8f04cd9972e8aa04ccd390f",
            "cbc35b43a8ad4a76af79ff8ac1dd14ff",
            "9ad6839f548a40018874da6370dc6402",
            "8effaea9d82646a19eacfaeda59f783d",
            "f922c1a630f149ab82e5b6fcecb2fd6d",
            "d2b1822ab520470885d6a400752ef580",
            "69de36023f5c45aa82a16dbb67b83433",
            "f47e2085dde34ce8a946912a28050457",
            "e9df0acd159c407f8a6d843ab26d57fe",
            "d8e6f2ae141144ac8f85207d66601c6e",
            "c2ce67d563c04f97810a9fcec7d6365c"
          ]
        },
        "outputId": "03fe5eed-3588-4c51-affe-eaa593bcc66c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "093f88ead8f04cd9972e8aa04ccd390f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../root/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/371e9839ca4e213dde891b066cf3080f75ec7e72/checkpoints/model.ckpt`\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "# Load the metrics\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "comet = evaluate.load(\"comet\")  # Ensure COMET is installed and properly configured\n",
        "chrf = evaluate.load(\"chrf\")  # ChrF metric\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "q7g_1_YRUBEb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_metrics(pred):\n",
        "    # Get predictions and labels\n",
        "    predictions = pred.predictions[0]\n",
        "    labels = pred.label_ids\n",
        "\n",
        "    # Decode predictions and labels\n",
        "    # Ensure predictions are flattened and contain token IDs:\n",
        "    predictions = predictions.argmax(-1)  # Assuming predictions are logits\n",
        "\n",
        "    if isinstance(predictions[0], list):\n",
        "        predictions = [item for sublist in predictions for item in sublist]\n",
        "\n",
        "    if isinstance(labels[0], list):\n",
        "        labels = [item for sublist in labels for item in sublist]\n",
        "\n",
        "\n",
        "    # Decode predictions and labels\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # BLEU\n",
        "    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    # ChrF\n",
        "    chrf_result = chrf.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    # ROUGE\n",
        "    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    #COMET\n",
        "    comet_result = comet.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "\n",
        "\n",
        "    # Combine all results into a dictionary\n",
        "    metrics = {\n",
        "        \"bleu\": bleu_result[\"bleu\"],\n",
        "        \"chrf\": chrf_result[\"score\"],\n",
        "        \"rouge1\": rouge_result[\"rouge1\"].fmeasure,\n",
        "        \"rouge2\": rouge_result[\"rouge2\"].fmeasure,\n",
        "        \"rougeL\": rouge_result[\"rougeL\"].fmeasure,\n",
        "        \"rougeLsum\": rouge_result.get(\"rougeLsum\", None),\n",
        "        \"comet\": comet_result.get(\"score\", None),\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO1dwIB0TdZI"
      },
      "source": [
        "### Training interpretation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0rkyWqoAOXs3"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "O6AnvT_7TdZI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c26bbdf9-8b6a-4a7c-abd4-db63d232ee82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t5-base'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model.name_or_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2BrFL5kYTdZI"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "\n",
        "# Set training arguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f'./results/{model_choice}',\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=9e-5,\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        "    #compute_metrics=compute_metrics,  # Add compute_metrics if you have it defined\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Gpu4DARFTdZI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "8c07cd73-15b2-4656-d462-35c9556ee333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1252' max='1252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1252/1252 03:56, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.006953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.291000</td>\n",
              "      <td>1.944724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.291000</td>\n",
              "      <td>1.940652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.839900</td>\n",
              "      <td>1.946915</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        }
      ],
      "source": [
        "if mode == 'train':\n",
        "  trainer.train()\n",
        "  # Save the model\n",
        "  model.save_pretrained(f'./results/{model_choice}/my_model')\n",
        "  tokenizer.save_pretrained(f'./results/{model_choice}/my_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WRH2vf5UVu2"
      },
      "source": [
        "### Interpretation Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Kj-0ol7SJi4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "a1a2de66-0aea-42bf-84b8-6b9516f98102"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.9406520128250122, 'eval_runtime': 1.7271, 'eval_samples_per_second': 181.229, 'eval_steps_per_second': 23.16, 'epoch': 4.0}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "mHS-L8DqR_27"
      },
      "outputs": [],
      "source": [
        "def classify_sarcasm(text):\n",
        "    inputs = classifier_tokenizer(text, return_tensors=\"pt\").to(device)  # Move inputs to the same device as the model\n",
        "    # Move the model to the same device as the inputs\n",
        "    classifier_model.to(device)\n",
        "    outputs = classifier_model(**inputs)\n",
        "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
        "    return prediction == 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2Fq-r3qFnWFD"
      },
      "outputs": [],
      "source": [
        "def inference(input_text):\n",
        "    # Clear prompt for the model\n",
        "    prompt = \"Rewrite this sarcastic comment as a factual statement: \"\n",
        "    if not input_text.startswith(prompt):\n",
        "        input_text = prompt + input_text\n",
        "\n",
        "    # Tokenize with padding and attention mask\n",
        "    inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    # Generate with increased diversity\n",
        "    output_ids = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=64,\n",
        "        early_stopping=True,\n",
        "        num_beams=5,              # Beam search for best results\n",
        "        temperature=0.7,           # Lower temperature for diversity\n",
        "        top_k=50,                  # Top-k sampling\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode the output, removing the instruction if it is repeated\n",
        "    decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    if decoded_output.startswith(prompt):\n",
        "        decoded_output = decoded_output[len(prompt):].strip()\n",
        "\n",
        "    return decoded_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ZH21T89-dxQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78f4d15-40e9-4492-c903-46c0dab9b573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation 0:\n",
            "Original: Schadenfreude x\n",
            "Sarcastic: No\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interpretation: <pad> Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude x Schadenfreude\n",
            "Ground Truth: After many years it is brilliant to laugh at germany \n",
            "--------------------\n",
            "Evaluation 1:\n",
            "Original: So, a country that is trillions in debt, with numbers approaching 13 million on surgical waiting lists and hurtling towards facism regime, is talking about rescuing people from a facist regime?\n",
            "Sarcastic: No\n",
            "Interpretation: <pad> a country that is trillions in debt, with numbers approaching 13 million on surgical waiting lists and hurtling towards facism regime, is talking about rescuing people from a facist regime? a country that is trillions in debt, with numbers approaching 13 million on surgical waiting lists, is\n",
            "Ground Truth: This country is not a \"free\" country anymore.\n",
            "--------------------\n",
            "Evaluation 2:\n",
            "Original: If anyone wants to know how my nights going I tried making a private story on Snapchat and instead made a group chat... I hate my life\n",
            "Sarcastic: No\n",
            "Interpretation: <pad> I made a private story on Snapchat and instead made a group chat. I hate my life. I made a private story on Snapchat and instead made a group chat. I hate my life. I made a private story on Snapchat and instead made a group chat. I hate my life.\n",
            "Ground Truth: this was the most embarrassing moment of my life.\n",
            "--------------------\n",
            "Evaluation 3:\n",
            "Original: don't make me rewatch panic \n",
            "Sarcastic: No\n",
            "Interpretation: <pad> Don't make me rewatch panic. Don't make me rewatch panic. Don't make me rewatch panic. Don't make me rewatch panic.\n",
            "Ground Truth: I'm going to rewatch panic on amazon\n",
            "--------------------\n",
            "Evaluation 4:\n",
            "Original: Yeah I'm following a lot of shows right now, the price is right is pretty good but season 1 is better than season 2\n",
            "Sarcastic: No\n",
            "Interpretation: <pad> I'm following a lot of shows right now, the price is right is pretty good but season 1 is better than season 2 I'm following a lot of shows right now, the price is right is pretty good but season 1 is better than season 2 I'm following a lot of shows\n",
            "Ground Truth: Stranger Things is pretty good but season 1 is better than season 2\n",
            "--------------------\n",
            "Evaluation 5:\n",
            "Original: What kind of sins have y'all been committing for God to punish us with this kinda weather...\n",
            "Sarcastic: No\n",
            "Interpretation: <pad> I'm not sure what kind of sins have y'all committed for God to punish us with this kinda weather. I'm not sure what kind of sins have y'all committed for God to punish us with this kinda weather. I'm not sure what kind of sin\n",
            "Ground Truth: God are you punishing us by creating such bad weather?\n",
            "--------------------\n",
            "Evaluation 6:\n",
            "Original: How does one find motivation to do basically anything? Asking for a friend.\n",
            "Sarcastic: No\n",
            "Interpretation: <pad> Asking for a friend is not motivating. Asking for a friend is not motivating. Asking for a friend is not motivating. Asking for a friend is not motivating.\n",
            "Ground Truth: \"How does somebody find motivation to do basically anything? I haven't had motivation in ages.\"\n",
            "--------------------\n",
            "Evaluation 7:\n",
            "Original: virgos are leos in a vest\n",
            "Sarcastic: No\n",
            "Interpretation: <pad> virgos are leos in a vest. They are leos in a vest. virgos are leos in a vest. virgos are leos in a vest. virgos are leos in a vest.\n",
            "Ground Truth: virgos act like leos\n",
            "--------------------\n",
            "Evaluation 8:\n",
            "Original: My (extended) fam was discussing going on a trip instead of getting presents for Christmas, like okay I'm bout it...\n",
            "Yeah they were talking about doing to the dells. I'll take my god damn presents thank you very much\n",
            "Sarcastic: No\n",
            "Interpretation: <pad> My extended fam was discussing going on a trip instead of getting presents for Christmas, like okay I'm bout it... Yeah they were talking about doing to the dells. I'll take my god damn presents thank you very much. My extended fam was talking about going on\n",
            "Ground Truth: Everyone needs gas-x after having beans. \n",
            "--------------------\n",
            "Evaluation 9:\n",
            "Original: All the shade i have been hearing about Ben Platt being unbelievable as a teenager in the @DearEvanHansen movie  boggles me.  Does nobody have any memories of Grease???  Name 1 actor on that film who believably looked high school age!\n",
            "Sarcastic: No\n",
            "Interpretation: <pad> I don't remember seeing Ben Platt in Grease as a teenager. I don't remember seeing him as a teenager. I don't remember seeing him as a teenager. I don't remember seeing him as a teenager. I don't remember seeing him as\n",
            "Ground Truth: Dear Evan Hanson cast the same type of older actors as Grease.\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "# Inference on a few test examples\n",
        "evaluation_texts = df_eval.sample(n=10, random_state=42)\n",
        "count = 0\n",
        "for index, row in evaluation_texts.iterrows():\n",
        "    is_sarcastic = classify_sarcasm(row['Sarcastic'])\n",
        "    print(f\"Evaluation {count}:\")\n",
        "    print(f\"Original: {row['Sarcastic']}\")\n",
        "    print(f\"Sarcastic: {'Yes' if is_sarcastic else 'No'}\")\n",
        "    if row['IsSarcastic'] == 1:\n",
        "      interpretation = inference(row['Sarcastic'])\n",
        "      print(f\"Interpretation: {interpretation}\")\n",
        "      print(f\"Ground Truth: {row['Translation']}\")\n",
        "    print(\"-\" * 20)\n",
        "    count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "AGMa1oOxeDWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d77691-3a04-421d-be18-8de051b7e054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src: Look at you, finishing all your snacks before dinner. What a healthy choice! \n",
            "translation: <pad> Finishing snacks before dinner is not a healthy choice. It's not a healthy choice. \n",
            "ground_truth: Eating snacks before dinner is not a good decision for your health.\n"
          ]
        }
      ],
      "source": [
        "src = \"Look at you, finishing all your snacks before dinner. What a healthy choice!\"\n",
        "truth = \"Eating snacks before dinner is not a good decision for your health.\"\n",
        "print(f\"src: {src} \\ntranslation: {inference(src)} \\nground_truth: {truth}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2t9q8GFYTdZC",
        "JSW3qxsmPrRK",
        "xASrnpTNTdZD",
        "Hl3dt9S4TdZF",
        "jdR7px1KTdZG",
        "Bq24u_dOP6QS",
        "CLvOvnvdP7kC",
        "_QzoDOLjQM7g",
        "uA7ONdyuQYZO",
        "AS-W87OVQjG6",
        "iFrUtrv0SAOe",
        "lO1dwIB0TdZI",
        "1WRH2vf5UVu2"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "093f88ead8f04cd9972e8aa04ccd390f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbc35b43a8ad4a76af79ff8ac1dd14ff",
              "IPY_MODEL_9ad6839f548a40018874da6370dc6402",
              "IPY_MODEL_8effaea9d82646a19eacfaeda59f783d"
            ],
            "layout": "IPY_MODEL_f922c1a630f149ab82e5b6fcecb2fd6d"
          }
        },
        "cbc35b43a8ad4a76af79ff8ac1dd14ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b1822ab520470885d6a400752ef580",
            "placeholder": "",
            "style": "IPY_MODEL_69de36023f5c45aa82a16dbb67b83433",
            "value": "Fetching5files:100%"
          }
        },
        "9ad6839f548a40018874da6370dc6402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f47e2085dde34ce8a946912a28050457",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9df0acd159c407f8a6d843ab26d57fe",
            "value": 5
          }
        },
        "8effaea9d82646a19eacfaeda59f783d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8e6f2ae141144ac8f85207d66601c6e",
            "placeholder": "",
            "style": "IPY_MODEL_c2ce67d563c04f97810a9fcec7d6365c",
            "value": "5/5[00:00&lt;00:00,333.93it/s]"
          }
        },
        "f922c1a630f149ab82e5b6fcecb2fd6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b1822ab520470885d6a400752ef580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69de36023f5c45aa82a16dbb67b83433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f47e2085dde34ce8a946912a28050457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9df0acd159c407f8a6d843ab26d57fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8e6f2ae141144ac8f85207d66601c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ce67d563c04f97810a9fcec7d6365c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}